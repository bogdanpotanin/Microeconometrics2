# --------
# Коссова Е.В., Потанин Б.С.
# Микроэконометрика качественных данных
# Тема 1. Классические модели бинарного выбора
# --------

# Отключим scientific notation
options(scipen = 999)

#---------------------------------------------------
# Симуляция данных
#---------------------------------------------------

# Воспроизведем процесс генерации данных, предполагаемый 
# классическими моделями бинарного выбора с линейным 
# индексом.

# Для удобства представим, что мы симулируем процесс,
# определяющий дефолт по кредиту.

# Симулируем данные
set.seed(123)                                        # для воспроизводимости
n <- 10000                                           # число индивидов в выборке
h <- data.frame(income = exp(rnorm(n, 10, 0.7)))     # доход
h$age = round(runif(n, 20, 100))                     # возраст
educ = t(rmultinom(n, 1, c(0.5, 0.3, 0.2)))          # уровень образования
h$educ_1 = as.numeric(educ[, 1] == 1)                # среднее образование
h$educ_2 = as.numeric(educ[, 2] == 1)                # среднее специальное образование
h$educ_3 <- as.numeric(educ[, 3] == 1)               # высшее образование
h$credit <- runif(n, 10000, 1000000)                 # объем кредита
h$stable <- rbinom(n, 1, 0.6)                        # стабильная работа
eps <- rnorm(n)                                      # случайная ошибка 
                                                         
beta <- c(8, -0.7, -0.02,                            # оцениваемые регрессионные 
          0.0001, -0.1, -0.3,                        # коэффициенты
          -0.5, 0.001, -0.1)   

default_li <- beta[1] + 
              beta[2] * log(h$income) +              # линейный индекс,
              beta[3] * h$age +                      # отражающий вклад наблюдаемых
              beta[4] * h$age ^ 2 +                  # факторов в вероятность дефолта
              beta[5] * h$educ_1 +
              beta[6] * h$educ_2 +
              beta[7] * h$educ_3 +
              beta[8] * sqrt(h$credit) +
              beta[9] * h$stable * log(h$income)

default_star <- default_li  + eps                    # латентная переменная,
                                                     # отражающая склонность
                                                     # к дефолту
# Создадим наблюдаемую зависимую переменную,
# отражающую факт дефолта
h$default <- as.numeric(default_star >= 0)           # наблюдаемое значение переменной
mean(h$default)                                      # доля дефолтов

#---------------------------------------------------
# Часть 1. Оценивание пробит и логит моделей
#---------------------------------------------------

# -----
# Учимся:
# 1. Оценивать коэффициенты при регрессорах в бинарных
#    уравнениях при помощи логит и пробит моделей
# 2. Интерпретировать знак и значимость коэффициентов
# 3. Строить асимптотические доверительные интервалы 
#    для коэффициентов
# -----

# Изучим данные
head(h, 10)

# --------------------------------------------
# Описание переменных:
# income  - доход
# age     - возраст
# educ_1  - среднее образование
# educ_2  - среднее специальное образование
# educ_3  - высшее образование
# credit  - объем кредита
# default - факт дефолта
# stable  - стабильная работа
# --------------------------------------------

# Пробит модель
model_probit <- glm(formula = default ~ log(income) +      # указываем формулу без константы, поскольку
                                        age + educ_3,      # она учитывается автоматически
                    data = h,                              # датафрейм, из которого берутся 
                                                           # зависимая и независимые переменные
                    family = binomial(link = "probit"))    # тип оцениваемой бинарной регрессии: в 
                                                           # данном случае пробит
summary(model_probit)                                      # посмотрим на результат

# Логит модель
model_logit <- glm(formula = default ~ log(income) +
                                       age + educ_3,
                   data = h,
                   family = binomial(link = "logit"))      # меняем только эту строку

summary(model_logit)

# Построим асимптотические доверительные
# интервалы для коэффициентов
confint(model_probit,                                      # модель
        level = 0.9)                                       # уровень доверия

# Отношение оценок коэффициентов логит и пробит 
# моделей обычно находится между 1.6 и 1.8
coef(model_logit) / coef(model_probit)

# ЗАДАНИЯ (* - средне, ** - сложно, *** - очень сложно)
# 1.1.    Используя пробит модель оцените вероятность 
#         дефолта в зависимости от:
#         1)    логарифма дохода и объема кредита.
#         2)    дохода, квадрата дохода и возраста.
#         3)    возраста и всех трех уровней образования.
#         4*)   логарифма дохода, возраста и стабильной
#               работы, учитывая, что влияние дохода может
#               зависеть от того, является ли работа
#               стабильной.
#         5*)   дохода и возраста без учета константы.
{
  # 1)
model1 <- glm(formula = default ~ log(income) + credit,
              data = h,
              family = binomial(link = "probit"))
summary(model1)    
  # 2)
model2 <- glm(formula = default ~ age +
                        income + I(income ^ 2),
              data = h,
              family = binomial(link = "probit"))
summary(model2)   
  # 3)
model3 <- glm(formula = default ~ age +                          # переменная educ_1 исключается во
                                  educ_2 + educ_3,               # избежание полной коллинеарности
              data = h,
              family = binomial(link = "probit"))
summary(model3)   
  # 4)
model4 <- glm(formula = default ~ log(income) + age + stable +   # данная спецификация может предполагать, например,                     
                                  I(log(income) * stable),       # что по мере роста дохода влияние объема кредита
              data = h,                                          # на вероятность дефолта снижается
              family = binomial(link = "probit"))
summary(model4)  
  # 5)
model5 <- glm(formula = default ~ income + age + 0,              # достаточно добавить '+ 0' в формулу
              data = h,
              family = binomial(link = "probit"))
summary(model5)
}
# 1.2. Оцените вероятность наличия у индивида высшего
#      образования в зависимости от дохода и возраста.
{
  model1 <- glm(formula = educ_3 ~ age + income,
                data = h,
                family = binomial(link = "probit"))
  summary(model1)    
}
# 1.3. Оцените вероятность дефолта в зависимости от 
#      возраста и квадратного корня из объема кредита 
#      используя логит модель, а затем постройте 80%-й
#      асимптотический доверительный интервал для
#      соответствующих коэффициентов
{
  model1 <- glm(formula = default ~ age + sqrt(credit),
                data = h,
                family = binomial(link = "logit"))
  summary(model1)   
  confint(model1, level = 0.8)
}
# 1.4. Используя встроенные данные Mroz87 из библиотеки
#      sampleSelection определите, как на вероятность
#      занятости (lfp) влияют возраст (age), образование (educ),
#      факт проживания в городе (city) и число несовершеннолетних
#      детей (kids5 и kids618).
{
  library("sampleSelection")                                     # подключаем библиотеку
  data(Mroz87)                                                   # скачиваем данные
  help(Mroz87)                                                   # информация о данных
  model1 <- glm(formula = lfp ~ age + educ + 
                                city + I(kids5 + kids618),
                data = Mroz87,
                family = binomial(link = "logit"))
  summary(model1)
}
# 1.5. Используя встроенные данные wage1 из библиотеки np постройте
#      модель, описывающую влияние почасовой зарплаты (wage), ее квадрата и
#      образования (educ) на вероятность брака (married)
#      Указание: предварительно преобразуйте переменную married в бинарную,
#                принимающую значение 1 для тех, кто состоит в браке и 
#                значение 0 - в противном случае.
{
  library("np")                                                  # подключаем библиотеку
  data(wage1)                                                    # скачиваем данные
  help(wage1)                                                    # информация о данных
  wage1$married <- wage1$married == "Married"                    # обработка данных
  model1 <- glm(formula = married ~ wage + I(wage ^ 2) + 
                                    educ,
                data = wage1,
                family = binomial(link = "logit"))
  
  summary(model1)
}

#---------------------------------------------------
# Часть 2. Оценивание вероятностей
#---------------------------------------------------

# -----
# Учимся:
# 1. Оценивать вероятность успеха в бинарных уравнениях
#    для индивидов из выборки и индивидов с конкретными,
#    заданными характеристиками
# 2. Тестировать гипотезы о вероятностях
# 3. Строить асимптотические доверительные интервалы 
#    для вероятностей
# -----

# Получим оценки (предсказанные значения) вероятностей
# дефолта для каждого индивида в выборке
default_prob <- predict(model_probit,                         # модель как объект, возвращаемый glm()
                        type = "response")                    # тип предсказания: в данном
head(default_prob, 10)                                        # случае вероятность

# Предскажем дефолт
default_est <- as.numeric(default_prob >= 0.5)  
defaul_df <- data.frame(true = h$default,                     # сравним истинные и
                        est = default_est)                    # предсказанные значения  
head(defaul_df)
                                                              
# Оценим точность предсказаний
mean(h$default == default_est)                                # доля верных предсказаний
default_p <- mean(h$default)                                  # доля дефолтов
max(default_p, 1 - default_p)                                 # верных предсказаний
                                                              # наивного прогноза

# Оценка вероятности занятости для конкретного индивида
Boris <- data.frame(income = 55000,                           # укажем характеристики
                    age = 35,                                 # Бориса в датафрейме
                    educ_3 = 1)
prob_Boris <- predict(model_probit,                           # объект возвращаемый glm()
                      newdata = Boris,                        # датафрейм, с использованием значений
                                                              # которого будут предсказаны вероятности
                      type = "response")                      # предсказываем вероятности

# Проверим гипотезу H0: P(У Бориса наступил дефолт = 0.25)
H0_prob <- 0.25
prob_Boris_se <- predict(model_probit,                        # достанем стандартную ошибку, то есть
                         newdata = Boris,                     # оценку асимптотического стандартного
                         type = "response",                   # отклонения вероятности занятости Бориса
                         se.fit = TRUE)$se.fit                # применяя аргумент se.fit       
z <- (prob_Boris - H0_prob) / prob_Boris_se                   # считаем статистку теста
p_value <- 2 * min(pnorm(z), 1 - pnorm(z))                    # p-value теста

# Построим симметричный асимптотический 90%-й доверительный
# интервал для вероятности занятости Бориса
ci <- prob_Boris + prob_Boris_se * qnorm(0.95) * c(-1, 1)

# ЗАДАНИЯ (* - средне, ** - сложно, *** - очень сложно)
# 2.1.    Для 28-летнего индивида без высшего образования
#         и с доходом 20000
#         1)     оцените вероятность дефолта
#         2)     постройте асимптотический 80%-й доверительный
#                интервал для вероятности дефолта
#         3)     проверьте гипотезу о том, что вероятность
#                дефолта равняется 0.5
{
  # 1)
  Sofia <- data.frame("income" = 20000, 
                      "age" = 28,
                      "educ_3" = 0)
  prob_Sofia <- predict(model_probit,
                        newdata = Sofia,
                        type = "response")
  # 2)
  H0_prob <- 0.5
  prob_Sofia_se <- predict(model_probit,
                           newdata = Sofia,
                           type = "response",
                           se.fit = TRUE)$se.fit
  z <- (prob_Sofia - H0_prob) / prob_Sofia_se
  2 * min(pnorm(z), 1 - pnorm(z))
  # 3)
  prob_Sofia + prob_Sofia_se * qnorm(0.95) * c(-1, 1)
}
# 2.2.    Рассчитайте вероятность дефолта для индивида
#         без высшего образования и:
#         1)    медианными возрастом и доходом
#         2)    средним возрастом и доходом
#         3*)   средним возрастом и логарифмом дохода
{
  # 1) 
  age_median <- median(h$age)
  income_median <- median(h$income)
  Sofia <- data.frame("income" = income_median,
                      "age" = age_median,
                      "educ_3" = 0)
  predict(model_probit, Sofia, "response")
  # 2)
  age_mean <- mean(h$age)
  income_mean <- mean(h$income)
  Sofia <- data.frame("income" = income_mean,
                      "age" = age_mean,
                      "educ_3" = 0)
  predict(model_probit, Sofia, "response")
  # 3)
  age_mean <- mean(h$age)
  lnincome_mean <- mean(log(h$income))
  Sofia <- data.frame("income" = exp(lnincome_median),
                      "age" = age_mean,
                      "educ_3" = 0)
  predict(model_probit, Sofia, "response")
}
# 2.3.    Не используя функцию predict() оцените для Бориса:
#         1*)   вероятность дефолта
#         2**)  оценку асимптотической дисперсии этой
#               вероятности (при помощи дельта метода)
{
  # 1)
  coef_probit <- coef(model_probit)                            # достаем оценки коэффициентов
  Boris_li <- coef_probit["(Intercept)"] +                     # оцениваем линейный индекс
              coef_probit["log(income)"] * log(Boris$income) +
              coef_probit["age"] * Boris$age + 
              coef_probit["educ_3"] * Boris$educ_3 
  prob_Boris <- pnorm(Boris_li)                                # оцениваем вероятность
  # 2)
  cov_probit <- vcov(model_probit)                             # достаем оценку асимптотической
                                                               # ковариационной матрицы оценок
                                                               # регрессионных коэффициентов
  grad_probit <- dnorm(Boris_li) * c(1, log(Boris$income),     # считаем градиент вероятности по 
                                     Boris$age, Boris$educ_3)  # оцениваемым параметрам
  sqrt(grad_probit %*% cov_probit %*% grad_probit)             # рассчитываем асимптотическое
                                                               # стандартное отклонение
}
# 2.4. Используя встроенные данные Mroz87 из библиотеки
#      sampleSelection оцените вероятность занятости
#      для двадцатилетней городской женщины с десятью годами
#      образования и двумя несовершеннолетними детьми
#
{
  library("sampleSelection")                          # подключаем библиотеку
  data(Mroz87)                                        # скачиваем данные
  help(Mroz87)                                        # информация о данных
  model1 <- glm(formula = lfp ~ age + educ +          # строим модель
                  city + I(kids5 + kids618),
                data = Mroz87,
                family = binomial(link = "logit"))
  Sofia <- data.frame(age = 20,                       # характеристики Софии
                      educ = 10,
                      city = 1,
                      kids5 = 2,
                      kids618 = 0)
  predict(model1, Sofia, "response")
}
# 2.5. Используя встроенные данные wage1 из библиотеки np оцените
#      вероятность брака для мужчины с пятнадцатью годами
#      образования и медианной почасовой оплатой труда
#      
{
library("np")                                             # подключаем библиотеку
data(wage1)                                               # скачиваем данные
help(wage1)                                               # информация о данных
wage1$married <- wage1$married == "Married"               # обработка данных
model1 <- glm(formula = married ~ wage + I(wage ^ 2) +    # строим модель
                educ,
              data = wage1,
              family = binomial(link = "logit"))
Artem <- data.frame(educ = 10,                            # характеристики Артема                       
                    wage = median(wage1$wage))
predict(model1, Artem, "response")
}
# 2.6. Рассчитайте долю индивидов в выборке, для которых
#      вероятность дефолта на уровне значимости 0.2
#      статистически значимо:
#      1*)   отличается от 0.5
#      2*)   превышает 0.5
{
  # 1) 
  H0_prob <- 0.5
  default_prob_se <- predict(model_probit,          # считаем стандартные ошибки
                          type = "response",        # вероятности занятости для всех
                          se.fit = TRUE)$se.fit     # индивидов в выборке
  z <- (default_prob - H0_prob) / default_prob_se   # считаем статистку теста
  mean(abs(z) > qnorm(0.9))
  # 2)
  mean(z > qnorm(0.8))
}

#---------------------------------------------------
# Часть 3. Оценивание предельных эффектов
#---------------------------------------------------

# -----
# Учимся:
# 1. Оценивать предельный эффект регрессоров на
#    вероятности
# 2. Строить асимптотические доверительные интервалы
#    для предельных эффектов на вероятность
# 3. Рассчитывать средний предельный эффект
# -----

library("margins")                             # библиотека для расчета
                                               # предельных эффектов

# Предельные эффекты
probit_me <- margins(model = model_probit,     # объект, возвращаемый glm(), в котором   
                                               # хранятся полученные нами ранее оценки
                     variables = NULL,         # переменная, по которой считается
                                               # предельный эффект: можно указать вектор
                                               # переменных или поставить NULL (по умолчанию), 
                                               # чтобы получить предельные эффекты сразу по 
                                               # всем независимым переменным
                     type = "response")        # на что строится предельный эффект:
                                               # вероятность или линейный индекс

# Посмотрим оценки предельных эффектов на 
# вероятность дефолта по каждой независимой 
# переменной, измеренной в непрерывной шкале
head(probit_me$dydx_income, 10)                # предельный эффект по доходу
head(probit_me$dydx_age, 10)                   # предельный эффект по возрасту
# Визуализируем распределение
# предельных эффектов
hist(probit_me$dydx_income, 
     main = "Распределение предельных эффектов
             дохода на вероятность дефолта",
     xlab = "Доход",
     ylab = "Предельный эффект",
     col = "cornsilk1")

# Корректно говорить о предельном эффекта высшего 
# образования как о разнице в вероятности занятости 
# для индивидов с идентичными характеристиками, но 
# различными уровнями образования
  # создадим датафрейм из людей 
  # с высшим образованием
h_1 <- model_probit$data                              # возьмем изначальный датафрейм и присвоим
h_1$educ_3 <- 1                                       # в нем всем индивидам высшее образование
prob_1 <- predict(model_probit, newdata = h_1,        # считаем вероятности занятости
                  type = "response")   
head(prob_1, 10)
  # создадим датафрейм из людей 
  # без высшего образования
h_0 <- model_probit$data                              # возьмем изначальный датафрейм и уберем в
h_0$educ_3 <- 0                                       # нем у всех индивидов высшее образование
prob_0 <- predict(model_probit, newdata = h_0,        # считаем вероятности занятости
                  type = "response")  
head(prob_0, 10)
  # оценим предельный эффект высшего образования 
  # для каждого индивида в выборке
ME_educ_3 <- prob_1 - prob_0
head(ME_educ_3, 10)

# По поводу средних предельных эффектов можно
# получить следующие результаты:
# factor - переменная, предельный эффект которой
#          на вероятность подлежит рассмотрению
# AME    - средний предельный эффект
# SE     - оценка асимптотического стандартного
#          отклонения среднего предельного эффекта
# p      - p-value теста о равенстве предельного
#          эффекта нулю
# level  - скольки процентный асимптотический
#          доверительный интервал должен быть 
#          построен
# lower  - нижняя граница (level * 100) процентного
#          асимптотического доверительно интервала
#          для предельного эффекта 
# upper  - верхняя граница (level * 100) процентного
#          асимптотического доверительно интервала
#          для предельного эффекта 
summary(probit_me,                                    # объект, возвращаемый функцией margins(), в котором
                                                      # хранятся полученные нами ранее оценки
        level = 0.9)                                  # скольки процентный асимптотический доверительный 
                                                      # интервал для предельного эффекта будет построен

# Оценим предельные эффекты для Бориса
Boris_me <- margins(model = model_probit, 
                    at = Boris, 
                    type = "response")
# По непрерывным переменным
summary(Boris_me)                                     # предельный эффект высшего образования
                                                      # в выдаче указан неправильно
# По высшему образованию
Boris_noeduc <- Boris                                 # создаем индивида идентичного Борису,
Boris_noeduc$educ_3 <- 0                              # но без высшего образования, а затем
prob_Boris_noeduc <- predict(model_probit,            # считаем его вероятность дефолта
                             Boris_noeduc, 
                             "response")
prob_Boris - prob_Boris_noeduc                        # рассчитываем предельный эффект

# ЗАДАНИЯ (* - средне, ** - сложно, *** - очень сложно)
# 3.1.    Для 28-летнего индивида без высшего образования
#         и с доходом 20000:
#         1)     оцените предельный эффект дохода
#                на вероятность дефолта
#         2)     постройте асимптотический 80%-й доверительный
#                интервал для данного предельного эффекта
#         3)     проверьте значимость данного предельного эффекта
#         4*)    проверьте гипотезу о том, что данный предельный
#                эффект равняется -0.1.
#         5)     оцените предельный эффект высшего образования
#                на вероятность занятости
#         6**)   проверьте гипотезу о значимости данного
#                предельного эффекта
{
  # 1-3)
  Sofia <- data.frame("income" = 20000, 
                      "age" = 28,
                      "educ_3" = 1)
  Sofia_me <- margins(model = model_probit, 
                      at = Sofia, 
                      type = "response")
  s <- summary(Sofia_me)
  # 4)
  H0_me <- -0.1
  z <- (s$AME["income"] - H0_me) / 
    s$SE["Var_dydx_income"]
  2 * min(pnorm(z), 1 - pnorm(z))
  # 5)
  Sofia_1 <- Sofia                              # София с образованием        
  Sofia_0 <- Sofia                              # София без образования
  Sofia_0$educ_3 <- 0
  prob_Sofia_1 <- predict(model_probit,         # вероятность дефолта для Софии
                          Sofia_1, "response")  # с образованием
  prob_Sofia_0 <- predict(model_probit,         # вероятность дефолта для Софии
                          Sofia_0, "response")  # без образования
  me <- prob_Sofia_1 - prob_Sofia_0
  # 6)
  li_Sofia_1 <- predict(model_probit,           # линейный индекс для Софии
                          Sofia_1, "link")      # с образованием
  li_Sofia_0 <- predict(model_probit,           # линейный индекс для Софии
                          Sofia_0, "link")      # без образования
  
  d_1 <- dnorm(li_Sofia_1)                      # функции плотности в точке
  d_0 <- dnorm(li_Sofia_0)                      # линейного индекса
  
  Sofia_x1 <- c(1, log(Sofia$income),           # характеристики Софии
                Sofia$age, 1)                   # с образованием
  Sofia_x0 <- c(1, log(Sofia$income),           # характеристики Софии
                Sofia$age, 0)                   # без образования
  
  grad_probit <- d_1 * Sofia_x1 -               # градиент по оцениваемым
                 d_0 * Sofia_x0                 # параметрам
  cov_probit <- vcov(model_probit)              # ковариационная матрица
  me_se <- sqrt(grad_probit %*%                 # стандартная ошибка
                cov_probit %*% grad_probit)     # предельного эффекта
  
  z <- me / me_se                               # статистика теста
  2 * min(pnorm(z), 1 - pnorm(z))               # p-value
}
# 3.2. Используя встроенные данные Mroz87 из библиотеки
#      sampleSelection оцените предельный эффект на вероятность
#      занятости для двадцатилетней городской женщины с десятью
#      годами образования и двумя несовершеннолетними детьми по
#      всем ее характеристикам
#
{
  library("sampleSelection")                          # подключаем библиотеку
  data(Mroz87)                                        # скачиваем данные
  help(Mroz87)                                        # информация о данных
  Mroz87$kids <- Mroz87$kids5 + Mroz87$kids618        # во избежание ошибки
                                                      # создадим новую переменную
  model1 <- glm(formula = lfp ~ age + educ +          # строим модель
                                city + kids,
                data = Mroz87,
                family = binomial(link = "logit"))
  Sofia <- data.frame(age = 20,                       # характеристики Софии
                      educ = 10,
                      city = 1,
                      kids = 2)
  predict(model1, Sofia, "response")
  Sofia_me <- margins(model = model1, 
                      at = Sofia, 
                      type = "response")
  summary(Sofia_me)   
}
# 3.3.    Используя встроенные данные wage1 из библиотеки np 
#         для мужчины с пятнадцатью годами образования и медианной 
#         почасовой оплатой труда оцените предельный эффект на
#         вероятность брака переменной, отражающей
#         1) образование (входит линейно)
#         2) почасовую оплату труда (входит квадратично)
{
  # 1-2)
  library("np")                                             # подключаем библиотеку
  data(wage1)                                               # скачиваем данные
  help(wage1)                                               # информация о данных
  wage1$married <- wage1$married == "Married"               # обработка данных
  model1 <- glm(formula = married ~ wage + I(wage ^ 2) +    # строим модель
                                    educ,
                data = wage1,
                family = binomial(link = "logit"))
  Artem <- data.frame(educ = 10,                            # характеристики Артема                       
                      wage = median(wage1$wage))
  predict(model1, Artem, "response")
  Artem_me <- margins(model = model1, 
                      at = Artem, 
                      type = "response")
  summary(Artem_me)   
}

#---------------------------------------------------
# Часть 4. Логистическая регрессия и 
#          отношение шансов
#---------------------------------------------------

# -----
# Учимся:
# 1. Оценивать изменение отношения шансов в логит модели
# 2. Строить асимптотические доверительные интервалы для 
#    изменения отношений шансов
# -----

# Оценим логистическую регрессию
model_logit <- glm(formula = default ~ log(income) + 
                                       educ_3 +
                                       age + I(age ^ 2),                                                 
                   data = h,                                         
                   
                   family = binomial(link = "logit"))         
summary(model_logit)

# Достанем оценки коэффицеинтов
coef_est <- model_logit$coefficients

# Отношение шансов - (вероятность успеха) / (вероятность неудачи)

# Оценим, во сколько раз, при прочих равных,
# изменится отношение шансов при
OR_lnincome <- exp(coef_est["log(income)"]) # изменении логарифма дохода на единицу
OR_educ_3 <- exp(coef_est["educ_3"])        # получении высшего образования
OR_age <- exp(coef_est["age"] +             # изменении возраста на единицу
              coef_est["I(age^2)"] +
              2 * coef_est["I(age^2)"] * 
              model_logit$data$age)
head(OR_age, 10)

# Построим асимптотические доверительные
# интервалы для отношений шансов
exp(confint(model_logit, level = 0.9))     
# для переменной возраст доверительный
# интервал строится неправильно, без учета
# того, что она входит не линейно

# ЗАДАНИЯ (* - средне, ** - сложно, *** - очень сложно)
# 4.1.    Добавьте в модель квадратный корень из объема
#         кредита и оцените:
#         1)    изменения отношений шансов при изменении
#               квадратного корня из объема кредита на 1
#         2*)   изменения отношений шансов при изменении
#               квадратного корня из объема кредита на 0.7
#         3*)   изменения отношений шансов при изменении
#               объема кредита с 62500 до 90000
#         4*)   добавьте в модель куб возраста и оцените, как
#               изменится отношение шансов при изменении
#               возраста индивида с 25 до 26 лет
#         5**)  используя дельта метод проверьте, на 5%-м уровне
#               значимости гипотезу о том, что при изменении возраста
#               тридцатилетного индивида на единицу отношение
#               шансов изменится, то есть будет отличаться от единицы
{
  # 1)
  model1 <- glm(formula = default ~ log(income) + 
                                    educ_3 +
                                    age + I(age ^ 2) +
                                    I(sqrt(credit)),                                                 
                data = h,                                         
                family = binomial(link = "logit"))
  my_coef <- model1$coefficients
  OR_1 <- exp(my_coef["I(sqrt(credit))"])              # оценка изменения
                                                       # отношений шансов
  # 2*)
  OR_2 <- exp(0.7 * my_coef["I(sqrt(credit))"])
  # 3*)
  OR_3 <- exp((sqrt(90000) - (sqrt(62500))) * my_coef["I(sqrt(credit))"])
  # 4*)
  model2 <- glm(formula = default ~ log(income) + 
                                    educ_3 +
                                    age + I(age ^ 2) + I(age ^ 3) +
                                    I(sqrt(credit)),                                                 
                data = h,                                         
                family = binomial(link = "logit"))
  my_coef <- model2$coefficients
  OR_4 <- exp(my_coef["age"] + my_coef["I(age^2)"] + my_coef["I(age^3)"] +           
              (2 * my_coef["I(age^2)"] + 
               3 * my_coef["I(age^3)"]) * model_logit$data$age +
              3 * my_coef["I(age^3)"] * model_logit$data$age ^ 2)
  # 5**)
  my_age <- 30
  OR_5 <- exp(my_coef["age"] + my_coef["I(age^2)"] +        # изменение отношения
              my_coef["I(age^3)"] +                         # шансов для возраста
              (2 * my_coef["I(age^2)"] + 
               3 * my_coef["I(age^3)"]) * my_age +
              3 * my_coef["I(age^3)"] * my_age ^ 2)
  age_cov <- vcov(model2)[c("age", "I(age^2)", "I(age^3)"), # ковариационная матрица
                          c("age", "I(age^2)", "I(age^3)")] # оценок коэффициентов
                                                            # при переменных на возраст
  OR_5_dage <- OR_5                                         # производные по
  OR_5_dage2 <- (1 + 2 * my_age) * OR_5                     # коэффициентам при
  OR_5_dage3 <- (1 + 3 * (my_age + my_age ^ 2)) * OR_5      # переменных на возраст
  OR_5_grad <- c(OR_5_dage, OR_5_dage2, OR_5_dage3)
  OR_5_se <- sqrt(OR_5_grad %*% age_cov %*% OR_5_grad)      # стандартная ошибка
                                                            # отношения шансов
  z <- (OR_5 - 1) / OR_5_se                                 # считаем статистку теста
  p_value <- 2 * min(pnorm(z), 1 - pnorm(z))                # p-value теста
}
# 4.2.    Используя встроенные данные Mroz87 из библиотеки sampleSelection 
#         оцените, как на отношение шансов занятости (lfp) влияет:
#         1)    изменение возраста (age) на единицу
#         2)    переезд в город (city)
#         3*)   дополнительные три года образования
{
  # 1)
  library("sampleSelection")                                     # подключаем библиотеку
  data(Mroz87)                                                   # скачиваем данные
  help(Mroz87)                                                   # информация о данных
  model1 <- glm(formula = lfp ~ age + educ + 
                  city + I(kids5 + kids618),
                data = Mroz87,
                family = binomial(link = "logit"))
  mycoef <- coef(model1)
  OR_1 <- exp(mycoef["age"])
  # 2)
  OR_2 <- exp(mycoef["city"])
  # 3)
  OR_3 <- exp(3 * mycoef["educ"])
}
# 4.3.    Используя встроенные данные wage1 из библиотеки np оцените, как
#         на отношение шансов брака (married) влияет почасовая зарплата (wage),
#         учитывая, что в регрессионное уравнение она входит с линейной и
#         квадратичной частями.
#         почасовая зарплата (wage), ее квадрат и образования (educ) влияют на 
#         отношение шансов брака (married).
#         Указание: предварительно преобразуйте переменную married в бинарную,
#         принимающую значение 1 для тех, кто состоит в браке и 
#         значение 0 - в противном случае.
{
  library("np")                                                  # подключаем библиотеку
  data(wage1)                                                    # скачиваем данные
  help(wage1)                                                    # информация о данных
  wage1$married <- wage1$married == "Married"                    # обработка данных
  model1 <- glm(formula = married ~ wage + I(wage ^ 2) + 
                                    educ,
                data = wage1,
                family = binomial(link = "logit"))
  mycoef <- coef(model1)
  OR_1 <- exp(mycoef["wage"] +             
              mycoef["I(wage^2)"] +
              2 * mycoef["I(wage^2)"] * 
              model1$data$wage)
}

#---------------------------------------------------
# Часть 5. Выбор оптимальной спецификации модели
#          на основании информационных критериев
#---------------------------------------------------

# -----
# Учимся:
# 1. Рассчитывать информационные критерии AIC и BIC
# 2. Сравнивать модели по информационным критериям
# -----

# Построим модель, учитывающую возможность квадратичного
# эффекта возраста на склонность к дефолту (линейный индекс)
model_probit1 <- glm(formula = default ~ log(income) + educ_3 +               
                                         age + I(age ^ 2),       # добавляем квадрат возраста
                         
                     data = h,                                   # датафрейм, из которого берутся зависимая
                                                                 # и независимые переменные
                     family = binomial(link = "probit"))         # тип оцениваемой бинарной регрессии: в данном
                                                                 # случае пробит
summary(model_probit1)                                           # посмотрим на результат

# Сравним модели по информационным критериям
AIC(model_probit)                                                # сравнение по AIC
AIC(model_probit1)
BIC(model_probit)                                                # сравнение по BIC
BIC(model_probit1)

# Рассчитаем AIC и BIC вручную для модели
# с квадратом возраста
ll <- as.numeric(logLik(model_probit1))                          # считаем логарифм правдоподобия
n_param <- length(model_probit1$coefficients)                    # рассчитываем число
                                                                 # оцениваемых параметров 
n <- nrow(model_probit1$data)                                    # посчитаем число наблюдений
model_probit1_AIC <- 2 * (n_param - ll)                          # вычисляем AIC
model_probit1_BIC <- log(n) * n_param - 2 * ll                   # вычисляем BIC

# ЗАДАНИЯ (* - средне, ** - сложно, *** - очень сложно)
# 5.1.    Ориентируясь на информационные критерии AIC и BIC
#         сделайте вывод о необходимости учета не только
#         квадрата возраста, но и:
#         1) куба возраста
#         2) различных уровней образования
#         3) стабильности работы, а также ее эффекта 
#            взаимодействия с логарифмом дохода
{
  # 1)
  model3 <- glm(formula = default ~ log(income) + educ_3 +               
                                    age + I(age ^ 2) +
                                    I(age ^ 3),
                
                data = h,                                   
                family = binomial(link = "probit"))         
  c(AIC(model_probit1), AIC(model3))
  c(BIC(model_probit1), BIC(model3))
  # 2)
  model2 <- glm(formula = default ~ log(income) +               
                                    age + I(age ^ 2) +
                                    educ_2 + educ_3,
                
                data = h,                                   
                family = binomial(link = "probit"))         
  c(AIC(model_probit1), AIC(model2))
  c(BIC(model_probit1), BIC(model2))
  # 3)
  model1 <- glm(formula = default ~ log(income) + educ_3 +               
                                    age + I(age ^ 2) +
                                    stable + I(stable * log(income)),
                       
                data = h,                                   
                family = binomial(link = "probit"))         
  c(AIC(model_probit1), AIC(model1))
  c(BIC(model_probit1), BIC(model1))
}
# 5.2.    На основании критерия AIC сделайте выбор между
#         пробит и логит моделями, в которых в качестве
#         регрессоров выступают возраст и доход
{
  model1 <- glm(formula = default ~ income + age,                 # логит модель        
                data = h,
                family = binomial(link = "probit"))
  model2 <- glm(formula = default ~ income + age,                 # пробит модель      
                data = h,
                family = binomial(link = "logit"))
  c(AIC(model1), AIC(model2))                                    # сравнение моделей
}
# 5.3.    Используя AIC и BIC сравните модель, в которой
#         возраст и доход влияют на склонность к дефолту 
#         линейно с моделью, в которой рассматриваются логарифмы
#         соответствующих независимых переменных
{
model1 <- glm(formula = default ~ income + age,
              data = h,                                   
              family = binomial(link = "probit"))        
model2 <- glm(formula = default ~ log(income) + log(age),
              data = h,                                   
              family = binomial(link = "probit")) 
c(AIC(model1), AIC(model2))
c(BIC(model1), BIC(model2))
}
# 5.4*.   Оцените возраст, начиная с которого предельный эффект
#         возраста на вероятность дефолта становится положительным,
#         то есть меняет знак
{
  -model_probit1$coefficients[c("age")] /
  (2 * model_probit1$coefficients[c("I(age^2)")])
}
# 5.5.    Сравните предсказательную силу моделей с квадратом 
#         возраста и без него
#         1)     на исходной выборке
#         2*)    разделив выборку в пропорции 70% к 30% на
#                тренировочную и тестовую: на тренировочной
#                строится модель, а по тестовой рассчитывается
#                точность прогноза
{
  # 1)
  mean((predict(model_probit, type = "response") >                 # доля верных прогнозов в
          0.5) == model_probit$data$default)                       # модели без квадрат возраста
  mean((predict(model_probit1, type = "response") >                # доля верных прогнозов в
          0.5) == model_probit$data$default)                       # модели с квадратом возраста
  # 2)
  n <- nrow(h)                                                     # общее число наблюдений
  set.seed(298)                                                    # для воспроизводимости
  train_ind <- sample(1:n, 0.7 * n)                                # случайным образом отбираем
                                                                   # 70% наблюдений в тренировочную
                                                                   # выборку
  h_train <- h[train_ind, ]                                        # тренировочная выборка
  h_test <- h[-train_ind, ]                                        # тестовая выборка
  
  # Модель с квадратом возраста
  model1 <- glm(formula = default ~ log(income) + educ_3 +               
                                    age + I(age ^ 2),
                       
                data = h_train,                                    # оцениваем параметры модели по                                   
                family = binomial(link = "probit"))                # тренировочной выборке
  
  # Модель без квадрата возраста
  model2 <- glm(formula = default ~ log(income) +               
                                    educ_3 + age,
                       
                data = h_train,                                    # оцениваем параметры модели по                                   
                family = binomial(link = "probit"))                # тренировочной выборке
  
  # Сравнение точнос и прогноза на тестовых выборках
  mean((predict(model1, type = "response", h_test) >               # доля верных прогнозов в
        0.5) == h_test$default)                                    # модели с квадратом возраста
  mean((predict(model2, type = "response", h_test) >               # доля верных прогнозов в
        0.5) == h_test$default)                                    # модели без квадрат возраста
}

#---------------------------------------------------
# Часть 6. Тестирование гипотез о параметрах при
#          помощи теста Вальда и теста отношения
#          правдоподобий
#---------------------------------------------------

# -----
# Учимся:
# 1. Тестировать гипотезы о нескольких параметрах
# 2. Проверять гипотезу о возможности построения
#    совместной модели для различных групп
# -----

library("lmtest")                                                  # дополнительные функции для 
                                                                   # тестирования гипотез

# Пример №1. Проверим гипотезу:
# H0: beta: age     = 0
#           age ^ 2 = 0

model_probit_R <- glm(formula = default ~ log(income) + educ_3,       
                      data = h,                                  
                      family = binomial(link = "probit"))         


# Сравним модели
summary(model_probit_R)                                            # с линейным эффектом возраста
summary(model_probit1)                                             # с квадратичным эффектом возраста

# Проверим гипотезу при помощи разных тестов,
# где p-value указан как "Pr(>Chisq)"
lrtest(model_probit1, model_probit_R)                              # тест отношения правдоподобий                        
waldtest(model_probit1, model_probit_R, test = "Chisq")            # теста Вальда

# Пример №2. Проверим гипотезу:
# H0: beta age     = -0.02
#          age ^ 2 = 0.0001

# Оценим ограниченную модель, учитывая ограничения за 
# счет использования фиксированных значений коэффициентов
# для возраста и возраста в квадрате, с помощью аргумента offset 
# в функции glm()
model_probit_R <- glm(formula = default ~ log(income) + educ_3,    # пишем часть формулы, в которой нет
                                                                   # переменных с фиксированными коэффициентами
                      data = h,
                      offset = I(-0.02 * age) +                    # фиксированная часть формулы, где
                               I(0.0001 * age ^ 2),                # на коэффициенты накладывается ограничение
                                                                   # нулевой гипотезой
                                                                   # параметрами, а задаются вручную
                      family = binomial(link = "probit"))

# Проверим гипотезу LR тестом
lrtest(model_probit1, model_probit_R)

# Пример №3. Проверим гипотезу: 
# H0: beta log(income) = 2 * educ_3
#          age ^ 2 = 0.0001

model_probit_R <- glm(formula = default ~ age +   
                                          I(log(income) + 
                                            educ_3 / 2),           # объединяем две переменных в одну
                      data = h,
                      offset = I(0.0001 * age ^ 2),                # ограничение на коэффициент при
                                                                   # квадрате возраста
                      family = binomial(link = "probit"))

# Проверим гипотезу LR тестом, поскольку функция
# waldtest() не учитывает ограничения, введенные 
# за счет аргумента offset в фукнции glm()
lrtest(model_probit, model_probit_R)

# Пример №4. Проверим, можно ли оценивать совместную модели
#            для людей с высшим образованием и без него:
# H0: коэффициенты в моделях для людей с высшим образованием
#     и без - не различаются

# Оцениваем модель только для людей с высшим образованием
model_probit_F1 <- glm(formula = default ~ log(income) + 
                                           age + I(age ^ 2),
                       data = h[h$educ_3 == 1, ],
                       family = binomial(link = "probit"))

# Оцениваем модель только для людей без высшего образования
model_probit_F0 <- glm(formula = default ~ log(income) + 
                                           age + I(age ^ 2),
                       data = h[h$educ_3 == 0, ],
                       family = binomial(link = "probit"))

# Визуальное сравнение коэффициентов
rbind(coef(model_probit_F1), coef(model_probit_F0))

# Считаем логарифмы правдоподобия полной и
# ограниченной моделей
lnL_F <- logLik(model_probit_F1) + logLik(model_probit_F0)       # логарифм правдоподобия полной модели
lnL_R <- logLik(model_probit1)                                   # логарифм правдоподобия ограниченной модели
r <- length(model_probit_F1$coefficients)                        # число ограничений
as.numeric(1 - pchisq(lnL_F - lnL_R, df = r))                    # p-value теста

# ЗАДАНИЯ (* - средне, ** - сложно, *** - очень сложно)
# 6.1.    Рассмотрим следующую модель:
model <- glm(formula = default ~ log(income) + 
                                 age + I(age ^ 2) +
                                 educ_2 + educ_3 +
                                 sqrt(credit) +
                                 stable,
                       data = h,
                       family = binomial(link = "probit"))
#         При помощи теста отношения правдоподобий (LR теста)
#         проверьте гипотезу о том, что:
#         1) образование не влияет на вероятность дефолта
#         2) ни образование ни возраст не влияют на
#            вероятность дефолта
#         3) среднее специальное и высшее образование оказывают
#            одинаковый эффект на вероятность дефолта
#         4) коэффициент при высшем образовании в три раза
#            больше коэффициента при среднем специальном, а также
#            объем кредита не влияет на вероятность дефолта
#         5) можно оценивать совместную модель для людей
#            со стабильной работой и без стабильной работы
{
  # 1)
  model1 <- glm(formula = default ~ log(income) + 
                                    age + I(age ^ 2) +
                                    sqrt(credit) +
                                    stable,
                data = h,
                family = binomial(link = "probit"))
  lrtest(model, model1)
  # 2)
  model2 <- glm(formula = default ~ log(income) + 
                                    sqrt(credit) +
                                    stable,
                data = h,
                family = binomial(link = "probit"))
  lrtest(model, model2)
  # 3)
  model3 <- glm(formula = default ~ log(income) + 
                                    age + I(age ^ 2) +
                                    I(educ_2 + educ_3) +
                                    sqrt(credit) +
                                    stable,
               data = h,
               family = binomial(link = "probit"))
  lrtest(model, model3)
  # 4)
  model4 <- glm(formula = default ~ log(income) + 
                                    age + I(age ^ 2) +
                                    I(educ_2 / 3 + educ_3) +
                                    stable,
                data = h,
                family = binomial(link = "probit"))
  lrtest(model, model4)
  # 5)
  model_F1 <- glm(formula = formula(model),
                  data = h[h$stable == 1, ],
                  family = binomial(link = "probit"))
  model_F0 <- glm(formula = formula(model),
                  data = h[h$stable == 0, ],
                  family = binomial(link = "probit"))
  lnL_F <- logLik(model_F1) + logLik(model_F0)       
  lnL_R <- logLik(model)
  r <- length(model_F1$coefficients)                       
  as.numeric(1 - pchisq(lnL_F - lnL_R, df = r))
}

#---------------------------------------------------
# Дополнительные материалы
#---------------------------------------------------

#---------------------------------------------------
# Часть 7. Тестирование гипотез о вероятностях
#          и предельных эффектах
#---------------------------------------------------

# Пусть помимо Бориса имеется 
# еще один индивид - Зинаида:
Zina <- data.frame("income" = 80000,                          # укажем характеристики
                   "age" = 20,                                # Зинаиды в датафрейме
                   "educ_3" = 0)

# Оценим для них вероятности дефолта,
# используя оценки полной модели
  # P(Дефолт Бориса)
p_Boris <- predict(model_probit, 
                   type = "response", 
                   newdata = Boris)
  # P(Дефолт Зинаиды)
p_Zina <- predict(model_probit, 
                  type = "response", 
                  newdata = Zina)
  # Разница вероятностей
p_diff <- p_Boris - p_Zina

# Пример №1. Проверим гипотезу о том, что вероятности
# дефолта для Бориса и Зинаиды совпадают
# H0: P(Дефолт Бориса) = P(Дефолт Зинаиды)
# Эквивалентная запись:
# H0: P(Дефолт Бориса) - P(Дефолт Зинаиды) = 0

# Будем использовать тест Вальда
# Проверяются гипотезы вида:
# H0: C(x) = 0
# Статистика теста:
# W = С(x)' * AsCov(C(x)) ^ (-1) * С(x), где:
# x - вектор параметров модели: в нашем 
#     случае gamma
# C(x) - вектор столбец из функций, накладывающих
#        ограничения на параметры
# r - число ограничений, совпадающее с числом 
#     строк вектора столбца C(x)
# При верной H0 статистика теста W имеет хи-квадрат
# распределение с r степенями свободы

# Напишем функцию, позволяющую дифференцировать 
# вероятность успеха (дефолта) по коэффициентам
probGrad <- function(model,                                   # объект, возвращаемый glm() 
                     newdata)                                 # датафрейм, содержащий информацию об
{                                                             # индивидах, для которых оцениваются
                                                              # вероятности
  beta_est <- coefficients(model)                             # оценки регрессионных коэффициентов
  m <- length(beta_est)                                       # число оцениваемых параметров

  y_li_est <- predict(model, newdata = newdata)               # оценка линейного индекса
  y_li_d <- dnorm(y_li_est)                                   # функция плотности в точке
                                                              # линейного индекса
  y_name <- model_probit$formula[[2]]                         # достаем имя зависимой переменной
  newdata[[y_name]] <- 1                                      # добавляем зависимую переменную в датафрейм
  
  X <- model.frame(formula = model$formula, data = newdata)   # создаем матрицу независимых переменных,
  X[[y_name]] <- NULL                                         # удаляя из нее зависимую переменную
  X <- cbind(1, X)                                            # а затем добавляем константу
                                                 
  n <- nrow(X)                                                # число наблюдений

  my_grad <- matrix(NA, n, m)                                 # матрица, в которой по строкам будут храниться
                                                              # градиенты функции по каждой из вероятностей
  for(i in 1:m)                                               # для каждого из оцениваемых параметров
  {                                                           # рассчитываем частные производные вероятностей
    my_grad[, i] <- X[, i] * y_li_d                           # по beta и рассчитываем значения градиента
  }
  
  colnames(my_grad) <- c("Intercept",                         # для удобства добавляем имена для
                         colnames(X[, -1]))                   # столбцов градиента
  
  return(my_grad)                                             # возвращаем градиент
}

# Рассчитаем градиенты вероятностей дефолта
# для Бориса и Зинаиды, а также для разности
# соответствующих вероятностей
pg_Boris <- probGrad(model_probit, Boris)                     # градиент по вероятности Бориса
pg_Zina <- probGrad(model_probit, Zina)                       # градиент по вероятности Зинаиды
pg_diff <- pg_Boris - pg_Zina                                 # градиент разности вероятностей
                                                              # занятости Бориса и Зинаиды как
                                                              # разность градиентов
# Расчитаем оценки асимптотической дисперсий
# разницы вероятностей дефолта Бориса и Зиниды
as_cov_beta <- vcov(model_probit)                             # достаем оценку асимптотической ковариационной
                                                              # матрицы оценок регрессионных коэффициентов
as_cov_pg_diff <- pg_diff %*% as_cov_beta %*% t(pg_diff)      # считаем оценку асимптотической дисперсии
                                                              # оценки разности вероятностей

# Рассчитаем тестовую статистику
W_stat <- p_diff * solve(as_cov_pg_diff) * p_diff             # статистика теста Вальда
p_value <- 1 - pchisq(W_stat, df = 1)                         # p-value теста Вальда

# Пример №2. Проверим гипотезу:
# H0: P(Дефолт Бориса) = P(Дефолт Зинаиды)
#     P(Дефолт Владимира) = 0.8
# Эквивалентная запись:
# H0: P(Дефолт Бориса) - P(Дефолт Зинаиды) = 0
#     P(Дефолт Владимира) - 0.8 = 0

# Добавим Владимира
Vlad <- data.frame("income" = 10000,                          # укажем характеристики
                   "age" = 30,                                # Владимира в датафрейме
                   "educ_3" = 0)

p_Vlad <- predict(model_probit,                               # вычисляем вероятность
                  type = "response",                          # занятости Владимира
                  newdata = Vlad)

pg_Vlad <- probGrad(model_probit, Vlad)                       # рассчитываем градиент вероятности
                                                              # занятости Владимира по оцениваемым
                                                              # параметрам

# Создадим вектор вида C(x)
p_new <- matrix(c(p_diff, p_Vlad - 0.8), ncol = 1)

# Расчитаем оценки асимптотической ковариационной
# матрицы ограничений
pg_new <- rbind(pg_diff,                                      # матрица, по строкам которой 
                pg_Vlad)                                      # расположены градиенты ограничений,
                                                              # то есть Якобиан
as_cov_pg_new <- pg_new %*% as_cov_beta %*% t(pg_new)         # оцениваем асимптотическую 
                                                              # ковариационную матрицу ограничений

# Рассчитаем тестовую статистику
W_stat <- t(p_new) %*% solve(as_cov_pg_new) %*% p_new         # статистика теста Вальда
p_value <- 1 - pchisq(W_stat, df = 2)                         # p-value теста Вальда

# Тестирование гипотез о предельных 
# эффектах осуществляется по аналогии

# Использование теста Вальда в данном случае позволило
# нам не искать максимум функции правдоподобия при
# сложном нелинейном ограничении

# ЗАДАНИЯ (* - непросто, ** - сложно, *** - брутально)
# 7.1.    Проверьте гипотезу о том, что:
#         1)    вероятность дефолта Бориса и Владимира
#               одинакова
#         2)    вероятность дефолта Бориса на 10% 
#               больше, чем у Бориса
#         3)    вероятность дефолта Бориса на 10% 
#               больше, чем у Бориса, а вероятность
#               занятости Зинаиды составляет 0.5
# 7.2.    Создайте еще двух индивидов и проверьте гипотезу
#         о том, что:
#         1*)   вероятности дефолта у всех пяти индивидов
#               совпадают
#         2*)   вероятность дефолта у ваших двух индивидов 
#               в сумме больше, чем вероятность дефолта Бориса
# 7.3.   Проверьте гипотезу о том, что:
#        1) Предельные эффекты возраста на вероятность дефолта
#           для Бориса и Зинаиды совпадают
#        2) Предельный эффект дохода на вероятность дефолта у 
#           Бориса в 2 раза больше, чем у Зинаиды

#---------------------------------------------------
# Часть 8. Тестирование гипотез о
#          функциональной форме
#---------------------------------------------------

library("numDeriv")                                      # библиотека для
                                                         # численного дифференцирования

# Допустим, что исследователь предполагает,
# что индекс выглядит следующим образом:
# y_li = X * beta + t1 * exp(X * beta) + 
#                   t2 * (X * beta) ^ 2,
# где t1 и t2 выступают в качестве 
# дополнительных оцениваемых параметров
# В таком случае тест о справедливости 
# предположения исследователя о том, что 
# индекс является линейным, то есть y_li = X * beta, 
# сводится к тесту о том, что:
# H0: t1 = 0
#     t2 = 0

# Для проверки данной гипотезы воспользуемся
# тестом множителей Лагранжа

# Запишем функцию правдоподобия для данной модели
ProbitNonlinearLnL <- function(x, y, X)                  # функция правдоподобия
{
  beta <- matrix(x[-c(1, 2)], ncol = 1)                  # вектор beta коэффициентов и
  t <- matrix(x[c(1, 2)], ncol = 1)                      # вектор дополнительных параметров  
                                                         # переводим в матрицу с одним столбцом
  y_li <- X %*% beta                                     # оценка линейного индекса
  y_est <- y_li + t[1] * exp(y_li) +                     # оценка математического ожидания 
    t[2] * y_li ^ 2                                      # латентной переменной
  
  n_obs <- nrow(X)                                       # количество наблюдений
  
  L_vec <- matrix(NA, nrow = n_obs,                      # вектор столбец вкладов наблюдений
                  ncol = 1)                              # в функцию правдоподобия
  
  is_y_0 <- y == 0                                       # вектор условий z = 0
  is_y_1 <- y == 1                                       # вектор условий z = 1
  
  L_vec[is_y_1] <- pnorm(y_est[is_y_1])                  # вклад наблюдений для которых zi = 1
  L_vec[is_y_0] <- 1 - pnorm(y_est[is_y_0])              # вклад наблюдений для которых zi = 0
  
  lnL <- sum(log(L_vec))                                 # логарифм функции правдоподобия
  
  return(lnL)
}
# Воспользуемся созданной функцией
# Получим Оценки модели при справедливом 
# ограничении, накладываемом нулевой гипотезой
beta_est <- coef(model_probit)                           # достаем оценки из обычной пробит
beta_R <- c(0, 0, beta_est)                              # модели и приравниваем значения
names(beta_R)[c(1, 2)] <- c("t1", "t2")                  # дополнительных параметров к значениям,
                                                         # предполагаемым нулевой гипотезой
# Создадим матрицу регрессоров
X_mat <- as.matrix(model.frame(model_probit))            # достаем датафрейм с регрессорами и
X_mat[, 1] <- 1                                          # первращаем его в матрицу, а также
colnames(X_mat)[1] <- "Intercept"                        # заменяем зависимую переменную на константу
y <- model_probit$data$default                           # сохраним зависимую переменную

# Применим функцию
lnL_R <- ProbitNonlinearLnL(beta_R,                      # считаем логарифм функции правоподобия
                            y,                           # при ограничениях, совпадающую с логарифмом
                            X_mat)                       # функции правдоподобия обычной пробит модели
                                                         
lnL_R_grad <- grad(func = ProbitNonlinearLnL,            # считаем градиент данной функции
                   x = beta_R, y = y, X = X_mat)         # численным методом
lnL_R_grad <- matrix(lnL_R_grad, ncol = 1)               # градиент как матрица с одним столбцом 
                   
lnL_R_hess <- hessian(func = ProbitNonlinearLnL,         # считаем Гессиан данной функции
                      x = beta_R,                        # численным методом
                      y = y, X = X_mat)
# Реализуем тест
LM_value <- t(lnL_R_grad) %*%                            # считаем статистику теста
  solve(-lnL_R_hess) %*%                                 # множителей Лагранжа
  lnL_R_grad
p_value <- 1 - pchisq(LM_value, df = 2)                  # рассчитываем p-value теста
                                                         # множителей Лагранжа

# ЗАДАНИЯ (* - непросто, ** - сложно, *** - брутально)
# 8.1.    Проверьте гипотезу о том, что:
#         1)    y_li = X * beta + t1 * sin(X * beta) + t2 * cos(X * beta)
#               H0: t1 = 0
#                   t2 = 0
#         2)    y_li = X * beta + t1 * (beta1 + ... + betaN + t2) ^ 2
#               H0: t1 = 0
#                   t2 = 0
#         3*)   y_li = X * beta + t1 * (beta1 + ... + betaN) ^ 2
#               H0: t1 = 1
#         4*)   Повторите предыдущие пункты симулировав данные таким образом,
#               чтобы в пунктах 1) и 2) соблюдалось t1 = 1, t2 = 2, а в пункте 3) 
#               выполнялось t1 = 2
#         5**)  Повторите предыдущие пункты с помощью LR теста
